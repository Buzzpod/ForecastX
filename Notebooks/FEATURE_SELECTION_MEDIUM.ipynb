{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will perform various forms of analysis to determine which features that are available to us may be most useful when training multivariate models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from Functions import tsPlot\n",
    "from copy import deepcopy as dc\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from skopt import gp_minimize\n",
    "from tqdm import tqdm  # for progress bar\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "from ta.trend import SMAIndicator, EMAIndicator, MACD\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.volatility import BollingerBands\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NVDA_OPEN</th>\n",
       "      <th>NVDA_HIGH</th>\n",
       "      <th>NVDA_LOW</th>\n",
       "      <th>NVDA_CLOSE</th>\n",
       "      <th>NVDA_VOLUME</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>4.225095</td>\n",
       "      <td>4.348957</td>\n",
       "      <td>4.225095</td>\n",
       "      <td>4.303082</td>\n",
       "      <td>7.941654e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>4.300790</td>\n",
       "      <td>4.339784</td>\n",
       "      <td>4.259502</td>\n",
       "      <td>4.330608</td>\n",
       "      <td>7.075387e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>4.307669</td>\n",
       "      <td>4.326019</td>\n",
       "      <td>4.213625</td>\n",
       "      <td>4.245738</td>\n",
       "      <td>5.970476e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>4.211332</td>\n",
       "      <td>4.284732</td>\n",
       "      <td>4.186100</td>\n",
       "      <td>4.254913</td>\n",
       "      <td>5.211632e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-11</th>\n",
       "      <td>4.277850</td>\n",
       "      <td>4.296200</td>\n",
       "      <td>4.135638</td>\n",
       "      <td>4.195275</td>\n",
       "      <td>6.066607e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            NVDA_OPEN  NVDA_HIGH  NVDA_LOW  NVDA_CLOSE   NVDA_VOLUME\n",
       "DATE                                                                \n",
       "2010-01-05   4.225095   4.348957  4.225095    4.303082  7.941654e+07\n",
       "2010-01-06   4.300790   4.339784  4.259502    4.330608  7.075387e+07\n",
       "2010-01-07   4.307669   4.326019  4.213625    4.245738  5.970476e+07\n",
       "2010-01-08   4.211332   4.284732  4.186100    4.254913  5.211632e+07\n",
       "2010-01-11   4.277850   4.296200  4.135638    4.195275  6.066607e+07"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the csv file into a pandas DataFrame\n",
    "df_ret = pd.read_csv('../DataManagement/daily_data.csv', parse_dates=['DATE'], index_col='DATE')\n",
    "\n",
    "# Drop everything except the columns we need for this scenario\n",
    "df_ret = df_ret.filter(['DATE', 'NVDA_OPEN', 'NVDA_HIGH', 'NVDA_LOW', 'NVDA_CLOSE', 'NVDA_VOLUME'])\n",
    "\n",
    "df_ret.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NVDA_OPEN</th>\n",
       "      <th>NVDA_HIGH</th>\n",
       "      <th>NVDA_LOW</th>\n",
       "      <th>NVDA_CLOSE</th>\n",
       "      <th>NVDA_VOLUME</th>\n",
       "      <th>SMA_20</th>\n",
       "      <th>SMA_50</th>\n",
       "      <th>EMA_20</th>\n",
       "      <th>EMA_50</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_signal</th>\n",
       "      <th>BB_upper</th>\n",
       "      <th>BB_middle</th>\n",
       "      <th>BB_lower</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-07-02</th>\n",
       "      <td>3.186024</td>\n",
       "      <td>3.188318</td>\n",
       "      <td>3.059868</td>\n",
       "      <td>3.085099</td>\n",
       "      <td>6.339869e+07</td>\n",
       "      <td>2.908938</td>\n",
       "      <td>2.900635</td>\n",
       "      <td>2.953446</td>\n",
       "      <td>2.972066</td>\n",
       "      <td>57.663951</td>\n",
       "      <td>0.049553</td>\n",
       "      <td>0.019496</td>\n",
       "      <td>3.159471</td>\n",
       "      <td>2.908938</td>\n",
       "      <td>2.658406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-03</th>\n",
       "      <td>3.085098</td>\n",
       "      <td>3.172261</td>\n",
       "      <td>3.082804</td>\n",
       "      <td>3.165380</td>\n",
       "      <td>2.390013e+07</td>\n",
       "      <td>2.928779</td>\n",
       "      <td>2.903250</td>\n",
       "      <td>2.973630</td>\n",
       "      <td>2.979647</td>\n",
       "      <td>61.019761</td>\n",
       "      <td>0.059685</td>\n",
       "      <td>0.027534</td>\n",
       "      <td>3.194115</td>\n",
       "      <td>2.928779</td>\n",
       "      <td>2.663443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-05</th>\n",
       "      <td>3.144736</td>\n",
       "      <td>3.158499</td>\n",
       "      <td>3.085099</td>\n",
       "      <td>3.133268</td>\n",
       "      <td>3.052594e+07</td>\n",
       "      <td>2.943345</td>\n",
       "      <td>2.907103</td>\n",
       "      <td>2.988834</td>\n",
       "      <td>2.985671</td>\n",
       "      <td>59.005034</td>\n",
       "      <td>0.064380</td>\n",
       "      <td>0.034903</td>\n",
       "      <td>3.219769</td>\n",
       "      <td>2.943345</td>\n",
       "      <td>2.666921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-06</th>\n",
       "      <td>3.110330</td>\n",
       "      <td>3.119505</td>\n",
       "      <td>3.039223</td>\n",
       "      <td>3.073630</td>\n",
       "      <td>4.171765e+07</td>\n",
       "      <td>2.960662</td>\n",
       "      <td>2.908571</td>\n",
       "      <td>2.996910</td>\n",
       "      <td>2.989121</td>\n",
       "      <td>55.349888</td>\n",
       "      <td>0.062568</td>\n",
       "      <td>0.040436</td>\n",
       "      <td>3.223851</td>\n",
       "      <td>2.960662</td>\n",
       "      <td>2.697474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-09</th>\n",
       "      <td>3.055280</td>\n",
       "      <td>3.069042</td>\n",
       "      <td>3.007111</td>\n",
       "      <td>3.032342</td>\n",
       "      <td>3.338807e+07</td>\n",
       "      <td>2.973278</td>\n",
       "      <td>2.909168</td>\n",
       "      <td>3.000284</td>\n",
       "      <td>2.990816</td>\n",
       "      <td>52.906453</td>\n",
       "      <td>0.057142</td>\n",
       "      <td>0.043778</td>\n",
       "      <td>3.224542</td>\n",
       "      <td>2.973278</td>\n",
       "      <td>2.722015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            NVDA_OPEN  NVDA_HIGH  NVDA_LOW  NVDA_CLOSE   NVDA_VOLUME  \\\n",
       "DATE                                                                   \n",
       "2012-07-02   3.186024   3.188318  3.059868    3.085099  6.339869e+07   \n",
       "2012-07-03   3.085098   3.172261  3.082804    3.165380  2.390013e+07   \n",
       "2012-07-05   3.144736   3.158499  3.085099    3.133268  3.052594e+07   \n",
       "2012-07-06   3.110330   3.119505  3.039223    3.073630  4.171765e+07   \n",
       "2012-07-09   3.055280   3.069042  3.007111    3.032342  3.338807e+07   \n",
       "\n",
       "              SMA_20    SMA_50    EMA_20    EMA_50        RSI      MACD  \\\n",
       "DATE                                                                      \n",
       "2012-07-02  2.908938  2.900635  2.953446  2.972066  57.663951  0.049553   \n",
       "2012-07-03  2.928779  2.903250  2.973630  2.979647  61.019761  0.059685   \n",
       "2012-07-05  2.943345  2.907103  2.988834  2.985671  59.005034  0.064380   \n",
       "2012-07-06  2.960662  2.908571  2.996910  2.989121  55.349888  0.062568   \n",
       "2012-07-09  2.973278  2.909168  3.000284  2.990816  52.906453  0.057142   \n",
       "\n",
       "            MACD_signal  BB_upper  BB_middle  BB_lower  \n",
       "DATE                                                    \n",
       "2012-07-02     0.019496  3.159471   2.908938  2.658406  \n",
       "2012-07-03     0.027534  3.194115   2.928779  2.663443  \n",
       "2012-07-05     0.034903  3.219769   2.943345  2.666921  \n",
       "2012-07-06     0.040436  3.223851   2.960662  2.697474  \n",
       "2012-07-09     0.043778  3.224542   2.973278  2.722015  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Simple Moving Averages (SMA)\n",
    "df_ret['SMA_20'] = SMAIndicator(df_ret['NVDA_CLOSE'], window=20).sma_indicator()\n",
    "df_ret['SMA_50'] = SMAIndicator(df_ret['NVDA_CLOSE'], window=50).sma_indicator()\n",
    "\n",
    "# Calculate Exponential Moving Averages (EMA)\n",
    "df_ret['EMA_20'] = EMAIndicator(df_ret['NVDA_CLOSE'], window=20).ema_indicator()\n",
    "df_ret['EMA_50'] = EMAIndicator(df_ret['NVDA_CLOSE'], window=50).ema_indicator()\n",
    "\n",
    "# Calculate Relative Strength Index (RSI)\n",
    "df_ret['RSI'] = RSIIndicator(df_ret['NVDA_CLOSE']).rsi()\n",
    "\n",
    "# Calculate Moving Average Convergence Divergence (MACD)\n",
    "macd = MACD(df_ret['NVDA_CLOSE'])\n",
    "df_ret['MACD'] = macd.macd()\n",
    "df_ret['MACD_signal'] = macd.macd_signal()\n",
    "\n",
    "# Calculate Bollinger Bands (BB)\n",
    "bollinger = BollingerBands(df_ret['NVDA_CLOSE'])\n",
    "df_ret['BB_upper'] = bollinger.bollinger_hband()\n",
    "df_ret['BB_middle'] = bollinger.bollinger_mavg()\n",
    "df_ret['BB_lower'] = bollinger.bollinger_lband()\n",
    "\n",
    "# Specify the date range\n",
    "start_date = '2012-06-30'\n",
    "end_date = '2023-06-30'\n",
    "\n",
    "# Slice the DataFrame for the desired date range\n",
    "df_ret = df_ret.loc[start_date:end_date].copy()\n",
    "\n",
    "df_ret.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_lstm(data, n_steps, column):\n",
    "    column_names = [column]\n",
    "    data = dc(data)  # make deep copy of the input data\n",
    "\n",
    "    for i in range(1, n_steps+1):\n",
    "        column_name = f'{column}(t-{i})'\n",
    "        column_names.append(column_name)\n",
    "        data[column_name] = data[column].shift(i)\n",
    "\n",
    "    data.dropna(inplace=True)\n",
    "    data = data.loc[:, data.columns.intersection(column_names)]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 7\n",
    "\n",
    "timeseries_columns = ['NVDA_CLOSE', 'NVDA_OPEN', 'NVDA_HIGH', 'NVDA_LOW', 'NVDA_VOLUME']\n",
    "indicator_columns = ['SMA_20', 'SMA_50', 'EMA_20', 'EMA_50', 'RSI', 'MACD', 'MACD_signal', 'BB_upper', 'BB_middle', 'BB_lower']\n",
    "\n",
    "# Same as the univariate case\n",
    "shifted_close = prepare_data_lstm(df_ret, lookback, 'NVDA_CLOSE')    \n",
    "\n",
    "# New: now we also perform the same procedure on each of the additional features that we wish to include in our X matrix\n",
    "shifted_open = prepare_data_lstm(df_ret, lookback, 'NVDA_OPEN')\n",
    "shifted_high = prepare_data_lstm(df_ret, lookback, 'NVDA_HIGH')\n",
    "shifted_low = prepare_data_lstm(df_ret, lookback, 'NVDA_LOW')\n",
    "shifted_volume = prepare_data_lstm(df_ret, lookback, 'NVDA_VOLUME')\n",
    "\n",
    "# Then the same process for all of the technical indicators we want to include in our X matrix\n",
    "shifted_SMA20 = prepare_data_lstm(df_ret, lookback, 'SMA_20')\n",
    "shifted_SMA50 = prepare_data_lstm(df_ret, lookback, 'SMA_50')\n",
    "shifted_EMA20 = prepare_data_lstm(df_ret, lookback, 'EMA_20')\n",
    "shifted_EMA50 = prepare_data_lstm(df_ret, lookback, 'EMA_50')\n",
    "shifted_RSI = prepare_data_lstm(df_ret, lookback, 'RSI')\n",
    "shifted_MACD = prepare_data_lstm(df_ret, lookback, 'MACD')\n",
    "shifted_MACD_SIGNAL = prepare_data_lstm(df_ret, lookback, 'MACD_signal')\n",
    "shifted_BB_UPPER = prepare_data_lstm(df_ret, lookback, 'BB_upper')\n",
    "shifted_BB_MIDDLE = prepare_data_lstm(df_ret, lookback, 'BB_middle')\n",
    "shifted_BB_LOWER = prepare_data_lstm(df_ret, lookback, 'BB_lower')\n",
    "\n",
    "# Now we convert the dataframes into numpy matrices\n",
    "shifted_close_np = shifted_close.to_numpy()\n",
    "shifted_open_np = shifted_open.to_numpy()\n",
    "shifted_high_np = shifted_high.to_numpy()\n",
    "shifted_low_np = shifted_low.to_numpy()\n",
    "shifted_volume_np = shifted_volume.to_numpy()\n",
    "shifted_SMA20_np = shifted_SMA20.to_numpy()\n",
    "shifted_SMA50_np = shifted_SMA50.to_numpy()\n",
    "shifted_EMA20_np = shifted_EMA20.to_numpy()\n",
    "shifted_EMA50_np = shifted_EMA50.to_numpy()\n",
    "shifted_RSI_np = shifted_RSI.to_numpy()\n",
    "shifted_MACD_np = shifted_MACD.to_numpy()\n",
    "shifted_MACD_SIGNAL_np = shifted_MACD_SIGNAL.to_numpy()\n",
    "shifted_BB_UPPER_np = shifted_BB_UPPER.to_numpy()\n",
    "shifted_BB_MIDDLE_np = shifted_BB_MIDDLE.to_numpy()\n",
    "shifted_BB_LOWER_np = shifted_BB_LOWER.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_scaler = StandardScaler()    # Scaler for price data\n",
    "volume_scaler = StandardScaler()    # Scaler for volume data\n",
    "indicator_scaler = StandardScaler()    # Scaler for indicators except MACD and MACD Signal\n",
    "macd_scaler = StandardScaler()    # Scaler for MACD\n",
    "macd_signal_scaler = StandardScaler()    # Scaler for MACD signal\n",
    "\n",
    "# Scale the price data\n",
    "shifted_open_np_scaled = price_scaler.fit_transform(shifted_open_np)\n",
    "shifted_high_np_scaled = price_scaler.fit_transform(shifted_high_np)\n",
    "shifted_low_np_scaled = price_scaler.fit_transform(shifted_low_np)\n",
    "shifted_close_np_scaled = price_scaler.fit_transform(shifted_close_np)\n",
    "\n",
    "# Scale the volume data\n",
    "shifted_volume_np_scaled = volume_scaler.fit_transform(shifted_volume_np)\n",
    "\n",
    "# Scale the indicators exc. MACD and MACD Signal\n",
    "shifted_SMA20_np_scaled = indicator_scaler.fit_transform(shifted_SMA20_np)\n",
    "shifted_SMA50_np_scaled = indicator_scaler.fit_transform(shifted_SMA50_np)\n",
    "shifted_EMA20_np_scaled = indicator_scaler.fit_transform(shifted_EMA20_np)\n",
    "shifted_EMA50_np_scaled = indicator_scaler.fit_transform(shifted_EMA50_np)\n",
    "shifted_RSI_np_scaled = indicator_scaler.fit_transform(shifted_RSI_np)\n",
    "shifted_BB_UPPER_np_scaled = indicator_scaler.fit_transform(shifted_BB_UPPER)\n",
    "shifted_BB_MIDDLE_np_scaled = indicator_scaler.fit_transform(shifted_BB_MIDDLE)\n",
    "shifted_BB_LOWER_np_scaled = indicator_scaler.fit_transform(shifted_BB_LOWER_np)\n",
    "\n",
    "# Scale MACD\n",
    "shifted_MACD_np_scaled = macd_scaler.fit_transform(shifted_MACD_np)\n",
    "\n",
    "# Scale MACD Signal\n",
    "shifted_MACD_SIGNAL_np_scaled = macd_signal_scaler.fit_transform(shifted_MACD_SIGNAL_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our y vector does not change in the multivariate case since we are still predicting the close prices\n",
    "y = shifted_close_np_scaled[:, 0]\n",
    "\n",
    "# Our X matrix does change though as we need to add additional dimensions to store the extra variables\n",
    "# We start by slicing out the time t column from each of the X components\n",
    "X_close = shifted_close_np_scaled[:, 1:]\n",
    "X_open = shifted_open_np_scaled[:, 1:]\n",
    "X_high = shifted_high_np_scaled[:, 1:]\n",
    "X_low = shifted_low_np_scaled[:, 1:]\n",
    "X_volume = shifted_volume_np_scaled[:, 1:]\n",
    "\n",
    "X_SMA20 = shifted_SMA20_np_scaled[:, 1:]\n",
    "X_SMA50 = shifted_SMA50_np_scaled[:, 1:]\n",
    "X_EMA20 = shifted_EMA20_np_scaled[:, 1:]\n",
    "X_EMA50 = shifted_EMA50_np_scaled[:, 1:]\n",
    "X_RSI = shifted_RSI_np_scaled[:, 1:]\n",
    "X_BB_UPPER = shifted_BB_UPPER_np_scaled[:, 1:]\n",
    "X_BB_MIDDLE = shifted_BB_MIDDLE_np_scaled[:, 1:]\n",
    "X_BB_LOWER = shifted_BB_LOWER_np_scaled[:, 1:]\n",
    "X_MACD = shifted_MACD_np_scaled[:, 1:]\n",
    "X_MACD_SIGNAL = shifted_MACD_SIGNAL_np_scaled[:, 1:]\n",
    "\n",
    "# Then we individually \"flip\" each X component so that it goes, for example, t-7, t-6, t-5....\n",
    "X_close = dc(np.flip(X_close, axis=1))\n",
    "X_open = dc(np.flip(X_open, axis=1))\n",
    "X_high = dc(np.flip(X_high, axis=1))\n",
    "X_low = dc(np.flip(X_low, axis=1))\n",
    "X_volume = dc(np.flip(X_volume, axis=1))\n",
    "\n",
    "X_SMA20 = dc(np.flip(X_SMA20, axis=1))\n",
    "X_SMA50 = dc(np.flip(X_SMA50, axis=1))\n",
    "X_EMA20 = dc(np.flip(X_EMA20, axis=1))\n",
    "X_EMA50 = dc(np.flip(X_EMA50, axis=1))\n",
    "X_RSI = dc(np.flip(X_RSI, axis=1))\n",
    "X_BB_UPPER = dc(np.flip(X_BB_UPPER, axis=1))\n",
    "X_BB_MIDDLE = dc(np.flip(X_BB_MIDDLE, axis=1))\n",
    "X_BB_LOWER = dc(np.flip(X_BB_LOWER, axis=1))\n",
    "X_MACD = dc(np.flip(X_MACD, axis=1))\n",
    "X_MACD_SIGNAL = dc(np.flip(X_MACD_SIGNAL, axis=1))\n",
    "\n",
    "# Finally, we combine each X component into a single X matrix with the shape (samples, time steps, features) i.e. (1251, 7, 4) in this case\n",
    "X = np.stack((\n",
    "    X_close, \n",
    "    X_open, \n",
    "    X_high, \n",
    "    X_low, \n",
    "    X_volume,\n",
    "    X_SMA20,\n",
    "    X_SMA50,\n",
    "    X_EMA20,\n",
    "    X_EMA50,\n",
    "    X_RSI,\n",
    "    X_BB_UPPER,\n",
    "    X_BB_MIDDLE,\n",
    "    X_BB_LOWER,\n",
    "    X_MACD,\n",
    "    X_MACD_SIGNAL\n",
    "    ), axis=-1)\n",
    "\n",
    "# Also, y currently has shape (1251) but it needs to have shape (1251, 1) in this framework\n",
    "y = y.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the split proportions first\n",
    "train_ratio = 0.80  # 80% of data for training\n",
    "valid_ratio = 0.15  # 15% of data for validation\n",
    "test_ratio = 0.05   # 5% of data for testing\n",
    "\n",
    "# First split: separate out the test set\n",
    "train_valid_index = int(len(X) * (train_ratio + valid_ratio))\n",
    "X_train_valid, X_test = X[:train_valid_index], X[train_valid_index:]\n",
    "y_train_valid, y_test = y[:train_valid_index], y[train_valid_index:]\n",
    "\n",
    "# Second split: separate out the validation set from the remaining data\n",
    "train_index = int(len(X_train_valid) * train_ratio / (train_ratio + valid_ratio))\n",
    "X_train, X_valid = X_train_valid[:train_index], X_train_valid[train_index:]\n",
    "y_train, y_valid = y_train_valid[:train_index], y_train_valid[train_index:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = torch.tensor(X_train).float(), torch.tensor(y_train).float()\n",
    "X_test, y_test = torch.tensor(X_test).float(), torch.tensor(y_test).float()\n",
    "X_valid, y_valid = torch.tensor(X_valid).float(), torch.tensor(y_valid).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]\n",
    "    \n",
    "train_dataset = TimeSeriesDataset(X_train, y_train)\n",
    "valid_dataset = TimeSeriesDataset(X_valid, y_valid)\n",
    "test_dataset = TimeSeriesDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 7, 15]) torch.Size([16, 1])\n"
     ]
    }
   ],
   "source": [
    "for _, batch in enumerate(train_loader):\n",
    "    x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "    print(x_batch.shape, y_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple yet effective method to determine if a feature should be included in the model. Correlation measures the degree of relationship between two variables. If a feature is highly correlated with the target variable, it's often beneficial to include it in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Close      Open      High       Low    Volume     SMA20  \\\n",
      "Close        1.000000  0.999349  0.999702  0.999709  0.075900  0.993292   \n",
      "Open         0.999349  1.000000  0.999738  0.999727  0.075455  0.993845   \n",
      "High         0.999702  0.999738  1.000000  0.999675  0.079995  0.993835   \n",
      "Low          0.999709  0.999727  0.999675  1.000000  0.071455  0.993261   \n",
      "Volume       0.075900  0.075455  0.079995  0.071455  1.000000  0.076169   \n",
      "SMA20        0.993292  0.993845  0.993835  0.993261  0.076169  1.000000   \n",
      "SMA50        0.982329  0.982757  0.983184  0.981945  0.081354  0.993783   \n",
      "EMA20        0.995182  0.995626  0.995666  0.995146  0.076626  0.999680   \n",
      "EMA50        0.986660  0.987105  0.987444  0.986340  0.081687  0.996435   \n",
      "RSI          0.057088  0.051143  0.051778  0.056674 -0.016010 -0.008195   \n",
      "BB_UPPER     0.992981  0.993522  0.993782  0.992776  0.086204  0.997730   \n",
      "BB_MIDDLE    0.993292  0.993845  0.993835  0.993261  0.076169  1.000000   \n",
      "BB_LOWER     0.987093  0.987656  0.987300  0.987284  0.062798  0.996266   \n",
      "MACD         0.408394  0.407053  0.404893  0.410981 -0.009008  0.324925   \n",
      "MACD_SIGNAL  0.409351  0.409748  0.406528  0.412450 -0.017047  0.347629   \n",
      "\n",
      "                SMA50     EMA20     EMA50       RSI  BB_UPPER  BB_MIDDLE  \\\n",
      "Close        0.982329  0.995182  0.986660  0.057088  0.992981   0.993292   \n",
      "Open         0.982757  0.995626  0.987105  0.051143  0.993522   0.993845   \n",
      "High         0.983184  0.995666  0.987444  0.051778  0.993782   0.993835   \n",
      "Low          0.981945  0.995146  0.986340  0.056674  0.992776   0.993261   \n",
      "Volume       0.081354  0.076626  0.081687 -0.016010  0.086204   0.076169   \n",
      "SMA20        0.993783  0.999680  0.996435 -0.008195  0.997730   1.000000   \n",
      "SMA50        1.000000  0.993912  0.999230 -0.048099  0.991491   0.993783   \n",
      "EMA20        0.993912  1.000000  0.996567  0.000121  0.997873   0.999680   \n",
      "EMA50        0.999230  0.996567  1.000000 -0.036540  0.994548   0.996435   \n",
      "RSI         -0.048099  0.000121 -0.036540  1.000000 -0.004851  -0.008195   \n",
      "BB_UPPER     0.991491  0.997873  0.994548 -0.004851  1.000000   0.997730   \n",
      "BB_MIDDLE    0.993783  0.999680  0.996435 -0.008195  0.997730   1.000000   \n",
      "BB_LOWER     0.990119  0.995355  0.992234 -0.012427  0.988191   0.996266   \n",
      "MACD         0.235931  0.334540  0.262486  0.496601  0.335231   0.324925   \n",
      "MACD_SIGNAL  0.247410  0.351238  0.275504  0.421385  0.353141   0.347629   \n",
      "\n",
      "             BB_LOWER      MACD  MACD_SIGNAL  \n",
      "Close        0.987093  0.408394     0.409351  \n",
      "Open         0.987656  0.407053     0.409748  \n",
      "High         0.987300  0.404893     0.406528  \n",
      "Low          0.987284  0.410981     0.412450  \n",
      "Volume       0.062798 -0.009008    -0.017047  \n",
      "SMA20        0.996266  0.324925     0.347629  \n",
      "SMA50        0.990119  0.235931     0.247410  \n",
      "EMA20        0.995355  0.334540     0.351238  \n",
      "EMA50        0.992234  0.262486     0.275504  \n",
      "RSI         -0.012427  0.496601     0.421385  \n",
      "BB_UPPER     0.988191  0.335231     0.353141  \n",
      "BB_MIDDLE    0.996266  0.324925     0.347629  \n",
      "BB_LOWER     1.000000  0.309554     0.338253  \n",
      "MACD         0.309554  1.000000     0.963367  \n",
      "MACD_SIGNAL  0.338253  0.963367     1.000000  \n"
     ]
    }
   ],
   "source": [
    "columns = ['Close', 'Open', 'High', 'Low', 'Volume','SMA20','SMA50','EMA20','EMA50','RSI','BB_UPPER','BB_MIDDLE','BB_LOWER','MACD','MACD_SIGNAL']\n",
    "\n",
    "# Select the t-1 timestep for each feature\n",
    "t_1_close = shifted_close_np_scaled[:, -1]\n",
    "t_1_open = shifted_open_np_scaled[:, -1]\n",
    "t_1_high = shifted_high_np_scaled[:, -1]\n",
    "t_1_low = shifted_low_np_scaled[:, -1]\n",
    "t_1_volume = shifted_volume_np_scaled[:, -1]\n",
    "\n",
    "t_1_SMA20 = shifted_SMA20_np_scaled[:, -1]\n",
    "t_1_SMA50 = shifted_SMA50_np_scaled[:, -1]\n",
    "t_1_EMA20 = shifted_EMA20_np_scaled[:, -1]\n",
    "t_1_EMA50 = shifted_EMA50_np_scaled[:, -1]\n",
    "t_1_RSI = shifted_RSI_np_scaled[:, -1]\n",
    "t_1_BB_UPPER = shifted_BB_UPPER_np_scaled[:, -1]\n",
    "t_1_BB_MIDDLE = shifted_BB_MIDDLE_np_scaled[:, -1]\n",
    "t_1_BB_LOWER = shifted_BB_LOWER_np_scaled[:, -1]\n",
    "t_1_MACD = shifted_MACD_np_scaled[:, -1]\n",
    "t_1_MACD_SIGNAL = shifted_MACD_SIGNAL_np_scaled[:, -1]\n",
    "\n",
    "# Combine into a 2D array\n",
    "data_t_1 = np.stack((t_1_close, \n",
    "                     t_1_open, \n",
    "                     t_1_high, \n",
    "                     t_1_low, \n",
    "                     t_1_volume,\n",
    "                     t_1_SMA20,\n",
    "                     t_1_SMA50,\n",
    "                     t_1_EMA20,\n",
    "                     t_1_EMA50,\n",
    "                     t_1_RSI,\n",
    "                     t_1_BB_UPPER,\n",
    "                     t_1_BB_MIDDLE,\n",
    "                     t_1_BB_LOWER,\n",
    "                     t_1_MACD,\n",
    "                     t_1_MACD_SIGNAL), axis=-1)\n",
    "\n",
    "# Create a dataframe\n",
    "df_t_1 = pd.DataFrame(data_t_1, columns=columns)\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix_t_1 = df_t_1.corr()\n",
    "print(correlation_matrix_t_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method involves training the model with all the features first, then for each feature, the values are permuted in the validation data and the decrease in the model score is computed. The features which cause the largest decrease in score are considered the most important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we want to understand the importance of multiple forms of time series data, i.e. open, close, high, low and volume on the performance of an LSTM model that we have already trained.\n",
    "\n",
    "As a result, the first step is to load in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(15, 128, batch_first=True, dropout=0.5)\n",
       "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimal Parameters\n",
    "hidden_size_optimal = 128\n",
    "num_stacked_layers_optimal = 1\n",
    "dropout_optimal = 0.5\n",
    "\n",
    "# Fixed parameters\n",
    "input_size = 15\n",
    "num_epochs = 20\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "# Define custom LSTM class (same as before)\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_stacked_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_stacked_layers = num_stacked_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_stacked_layers, \n",
    "                            batch_first=True, dropout=dropout)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        h0 = torch.zeros(self.num_stacked_layers, batch_size, self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_stacked_layers, batch_size, self.hidden_size).to(device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Initialize the model\n",
    "model_optimal = LSTM(input_size, hidden_size_optimal, num_stacked_layers_optimal, dropout_optimal)\n",
    "model_optimal.to(device)\n",
    "\n",
    "# Load the saved model\n",
    "model_optimal.load_state_dict(torch.load(\"../Models/MvLSTM/28-07-2023_10-49-44/MvLSTM.pth\"))    # choose which saved model to load\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model_optimal.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New we have loaded the LSTM model, we can implement our permutation importance procedure using the eli5 library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Our features are 'Close', 'Open', 'High', 'Low', 'Volume'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Close</td>\n",
       "      <td>-0.016998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Open</td>\n",
       "      <td>-0.002097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>High</td>\n",
       "      <td>-0.011073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Low</td>\n",
       "      <td>-0.020116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Volume</td>\n",
       "      <td>0.000405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SMA20</td>\n",
       "      <td>-0.003552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SMA50</td>\n",
       "      <td>-0.007731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EMA20</td>\n",
       "      <td>-0.011972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EMA50</td>\n",
       "      <td>-0.006716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RSI</td>\n",
       "      <td>-0.022038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BB_UPPER</td>\n",
       "      <td>-0.013607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BB_MIDDLE</td>\n",
       "      <td>-0.005050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BB_LOWER</td>\n",
       "      <td>-0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MACD</td>\n",
       "      <td>-0.081030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MACD_SIGNAL</td>\n",
       "      <td>0.010476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Column  Importance\n",
       "0         Close   -0.016998\n",
       "1          Open   -0.002097\n",
       "2          High   -0.011073\n",
       "3           Low   -0.020116\n",
       "4        Volume    0.000405\n",
       "5         SMA20   -0.003552\n",
       "6         SMA50   -0.007731\n",
       "7         EMA20   -0.011972\n",
       "8         EMA50   -0.006716\n",
       "9           RSI   -0.022038\n",
       "10     BB_UPPER   -0.013607\n",
       "11    BB_MIDDLE   -0.005050\n",
       "12     BB_LOWER   -0.000003\n",
       "13         MACD   -0.081030\n",
       "14  MACD_SIGNAL    0.010476"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def score(X, y):\n",
    "    model_optimal.eval()\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    with torch.no_grad():\n",
    "        y_pred = model_optimal(X).detach().cpu().numpy()\n",
    "    return np.sqrt(mean_squared_error(y.cpu().numpy(), y_pred))\n",
    "\n",
    "baseline = score(X_valid, y_valid)\n",
    "imp = []\n",
    "for feature in range(X_valid.shape[2]):  # Iterate over features, not sequence steps\n",
    "    save = X_valid[:, :, feature].clone()  # Use clone for PyTorch tensor\n",
    "    X_valid[:, :, feature] = torch.tensor(np.random.permutation(X_valid[:, :, feature].cpu().numpy()), device=device)  # Convert back to tensor after permutation\n",
    "    m = score(X_valid, y_valid)\n",
    "    X_valid[:, :, feature] = save  # Restore original values\n",
    "    imp.append(baseline - m)\n",
    "\n",
    "# Create a DataFrame from the lists\n",
    "df_perm_imp = pd.DataFrame({'Column': columns, 'Importance': imp})\n",
    "\n",
    "# Display the transposed DataFrame\n",
    "display(df_perm_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permutation feature importance is a technique used to determine the most important features in our dataset. It works by shuffling the values of each feature and measuring how much the performance of the model decreases. The more the performance decreases, the more important the feature is.\n",
    "\n",
    "Now to interpret these specific results:\n",
    "\n",
    "* **Close:** The \"Close\" feature has a negative permutation importance of approximately -0.017. This suggests that the LSTM model relies somewhat on the original order of the \"Close\" values for making predictions. If you were to randomly shuffle the \"Close\" values, the model's performance would decrease by around 1.7%.\n",
    "\n",
    "* **Open:** The \"Open\" feature has a negative permutation importance of approximately -0.002. Similar to \"Close,\" the LSTM model also relies slightly on the order of \"Open\" values for making predictions. Shuffling \"Open\" values would lead to a performance decrease of about 0.2%.\n",
    "\n",
    "* **High and Low:** The \"High\" and \"Low\" features have negative permutation importances of -0.011 and -0.020, respectively. Both features seem to be slightly more important than \"Open\" and \"Close,\" indicating that the model uses the order of \"High\" and \"Low\" values to some extent in its predictions.\n",
    "\n",
    "* **Volume:** The \"Volume\" feature has a positive permutation importance of approximately 0.0004. This value is close to zero, suggesting that the model is not strongly reliant on the order of \"Volume\" values for making predictions.\n",
    "\n",
    "* **SMA20 and SMA50:** The \"SMA20\" and \"SMA50\" features have negative permutation importances of -0.0036 and -0.0077, respectively. These moving average features have a small impact on the model's performance, but they are still considered somewhat relevant.\n",
    "\n",
    "* **EMA20 and EMA50:** The \"EMA20\" and \"EMA50\" features have negative permutation importances of -0.012 and -0.0067, respectively. Like the SMA features, the exponential moving averages have a small influence on the model.\n",
    "\n",
    "* **RSI:** The \"RSI\" feature has a negative permutation importance of -0.022, indicating that it has a slightly larger impact on the model's predictions compared to other features mentioned above.\n",
    "\n",
    "* **BB_UPPER, BB_MIDDLE, and BB_LOWER:** The Bollinger Bands features have negative permutation importances, suggesting they have some influence on the model's predictions, but their impact is not substantial.\n",
    "\n",
    "* **MACD:** The \"MACD\" feature has a significant negative permutation importance of approximately -0.081. This indicates that the model heavily relies on the original order of the MACD values for making predictions.\n",
    "\n",
    "* **MACD_SIGNAL:** The \"MACD_SIGNAL\" feature has a positive permutation importance of approximately 0.010, which is relatively small compared to the negative impact of \"MACD.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
